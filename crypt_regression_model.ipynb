{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install numpy pandas matplotlib seaborn scikit-learn statsmodels joblib\n",
    "%pip install datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import warnings\n",
    "import joblib\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "# ─── suppress warnings ─────────────────────────────────────────────────────────\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "# ─── directories ───────────────────────────────────────────────────────────────\n",
    "PROJECT_DIR    = os.path.expanduser(\"~/User/crypto proj\")\n",
    "PREPROCESS_DIR = os.path.join(PROJECT_DIR, \"data\", \"preprocessed\")\n",
    "INFO_PATH      = os.path.join(PREPROCESS_DIR, \"preprocessing_info.json\")\n",
    "RESULTS_DIR    = os.path.join(PROJECT_DIR, \"regression_results\")\n",
    "MODEL_DIR      = os.path.join(PROJECT_DIR, \"models\")\n",
    "PLOTS_DIR      = os.path.join(PROJECT_DIR, \"visualizations\", \"regression\")\n",
    "\n",
    "for d in (PREPROCESS_DIR, RESULTS_DIR, MODEL_DIR, PLOTS_DIR):\n",
    "    os.makedirs(d, exist_ok=True)\n",
    "\n",
    "# ─── constants ────────────────────────────────────────────────────────────────\n",
    "TARGET       = \"Target_Next_Day\"\n",
    "TEST_SIZE    = 0.2\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# ─── load symbol list ───────────────────────────────────────────────────────────\n",
    "with open(INFO_PATH, 'r') as f:\n",
    "    info    = json.load(f)\n",
    "SYMBOLS = list(info['Total Records'].keys())  # e.g. ['BTC','ETH','DOGE']\n",
    "\n",
    "# ─── helper functions ──────────────────────────────────────────────────────────\n",
    "def load_latest(symbol: str) -> pd.DataFrame:\n",
    "    \"\"\"Load the most recent preprocessed CSV for a symbol.\"\"\"\n",
    "    pattern = os.path.join(PREPROCESS_DIR, f\"{symbol}_preprocessed_*.csv\")\n",
    "    paths   = glob.glob(pattern)\n",
    "    if not paths:\n",
    "        raise FileNotFoundError(f\"No preprocessed files found for {symbol}\")\n",
    "    latest = max(paths, key=os.path.getmtime)\n",
    "    print(f\"Loaded {os.path.basename(latest)} for {symbol}\")\n",
    "    df = pd.read_csv(latest, parse_dates=[\"Date\"], index_col=\"Date\")\n",
    "    return df\n",
    "\n",
    "def prepare_data(df: pd.DataFrame):\n",
    "    \"\"\"Return chronological train/test split of features and target.\"\"\"\n",
    "    X = df.select_dtypes(include=[np.number]).drop(\n",
    "        [\"Target_Next_Day\",\"Target_Next_Week\",\"Target_Next_Month\"], axis=1, errors=\"ignore\"\n",
    "    ).dropna()\n",
    "    y = df.loc[X.index, TARGET]\n",
    "    return train_test_split(X, y, test_size=TEST_SIZE, shuffle=False)\n",
    "\n",
    "def evaluate_metrics(y_true, y_pred):\n",
    "    \"\"\"Compute RMSE, MAE, R2.\"\"\"\n",
    "    return {\n",
    "        \"RMSE\": mean_squared_error(y_true,   y_pred, squared=False),\n",
    "        \"MAE\":  mean_absolute_error(    y_true,   y_pred),\n",
    "        \"R2\":   r2_score(              y_true,   y_pred)\n",
    "    }\n",
    "\n",
    "def plot_bar(series, title, out_path):\n",
    "    \"\"\"Bar plot with value labels.\"\"\"\n",
    "    ax = series.sort_values().plot.bar(title=title, figsize=(8,4))\n",
    "    ax.bar_label(ax.containers[0], fmt=\"%.2f\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_path)\n",
    "    plt.close()\n",
    "\n",
    "def plot_actual_vs_pred(y_true, y_pred, symbol, model_name):\n",
    "    \"\"\"Time-series plot of actual vs predicted.\"\"\"\n",
    "    plt.figure(figsize=(10,4))\n",
    "    plt.plot(y_true.index, y_true, label=\"Actual\")\n",
    "    plt.plot(y_true.index, y_pred, label=\"Predicted\", alpha=0.7)\n",
    "    plt.title(f\"{symbol} — {model_name}\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(PLOTS_DIR, f\"{symbol}_{model_name}_pred.png\"))\n",
    "    plt.close()\n",
    "\n",
    "def save_feature_importance(model, features, symbol, model_name):\n",
    "    \"\"\"If model has feature_importances_, save them to CSV.\"\"\"\n",
    "    if hasattr(model, \"feature_importances_\"):\n",
    "        imp = pd.Series(model.feature_importances_, index=features).sort_values(ascending=False)\n",
    "        imp.to_csv(os.path.join(RESULTS_DIR, f\"{symbol}_{model_name}_feat_imp.csv\"))\n",
    "\n",
    "def fit_and_evaluate(name, estimator, param_grid, X_tr, y_tr, X_te, y_te):\n",
    "    \"\"\"\n",
    "    Fit estimator (with optional grid search), evaluate on test set,\n",
    "    return fitted model, metrics dict, and y_pred.\n",
    "    \"\"\"\n",
    "    if param_grid:\n",
    "        gs = GridSearchCV(estimator, param_grid, cv=5, n_jobs=-1, scoring=\"r2\")\n",
    "        gs.fit(X_tr, y_tr)\n",
    "        model = gs.best_estimator_\n",
    "        print(f\"  {name} best params: {gs.best_params_}\")\n",
    "    else:\n",
    "        model = estimator.fit(X_tr, y_tr)\n",
    "\n",
    "    y_pred  = model.predict(X_te)\n",
    "    metrics = evaluate_metrics(y_te, y_pred)\n",
    "    return model, metrics, y_pred\n",
    "\n",
    "# ─── model configurations ──────────────────────────────────────────────────────\n",
    "scaler_step = (\"scaler\", StandardScaler())\n",
    "MODELS = {\n",
    "    \"Linear\":     (Pipeline([scaler_step, (\"model\", LinearRegression())]), {}),\n",
    "    \"Ridge\":      (Pipeline([scaler_step, (\"model\", Ridge(max_iter=10000))]),\n",
    "                   {\"model__alpha\":[0.001,0.01,0.1,1,10]}),\n",
    "    \"Lasso\":      (Pipeline([scaler_step, (\"model\", Lasso(max_iter=50000, tol=1e-3))]),\n",
    "                   {\"model__alpha\":[0.001,0.01,0.1,1]}),\n",
    "    \"ElasticNet\": (Pipeline([scaler_step, (\"model\", ElasticNet(max_iter=50000, tol=1e-3))]),\n",
    "                   {\"model__alpha\":[0.001,0.01,0.1], \"model__l1_ratio\":[0.2,0.5,0.8]}),\n",
    "    \"SVR\":        (Pipeline([scaler_step, (\"model\", SVR())]),\n",
    "                   {\"model__C\":[0.1,1,10], \"model__epsilon\":[0.01,0.1,1]}),\n",
    "    \"GBR\":        (GradientBoostingRegressor(random_state=RANDOM_STATE), {}),\n",
    "    \"RF\":         (RandomForestRegressor(n_estimators=200, random_state=RANDOM_STATE), {})\n",
    "}\n",
    "\n",
    "# ─── main routine ──────────────────────────────────────────────────────────────\n",
    "def main():\n",
    "    summary = []\n",
    "\n",
    "    print(\"Starting regression pipeline...\\n\")\n",
    "    for sym in SYMBOLS:\n",
    "        print(f\"=== Processing {sym} ===\")\n",
    "        df = load_latest(sym)\n",
    "        X_tr, X_te, y_tr, y_te = prepare_data(df)\n",
    "        print(f\"Data split: X_train={X_tr.shape}, X_test={X_te.shape}\\n\")\n",
    "\n",
    "        metrics_dict = {}\n",
    "        for name, (est, params) in MODELS.items():\n",
    "            print(f\"-->> Training {name}\")\n",
    "            model, mets, y_pred = fit_and_evaluate(name, est, params, X_tr, y_tr, X_te, y_te)\n",
    "            print(f\"   {name} metrics: R2={mets['R2']:.4f}, RMSE={mets['RMSE']:.2f}, MAE={mets['MAE']:.2f}\\n\")\n",
    "            metrics_dict[name] = mets\n",
    "\n",
    "            # persist model and outputs\n",
    "            joblib.dump(model, os.path.join(MODEL_DIR, f\"{sym}_{name}.pkl\"))\n",
    "            plot_actual_vs_pred(y_te, y_pred, sym, name)\n",
    "            save_feature_importance(model, X_tr.columns, sym, name)\n",
    "\n",
    "        # metrics DataFrame\n",
    "        dfm = pd.DataFrame(metrics_dict).T[[\"RMSE\",\"MAE\",\"R2\"]]\n",
    "        dfm.to_csv(os.path.join(RESULTS_DIR, f\"{sym}_metrics.csv\"))\n",
    "\n",
    "        # plot metrics\n",
    "        plot_bar(dfm[\"R2\"],  f\"{sym} test R²\",  os.path.join(PLOTS_DIR, f\"{sym}_r2.png\"))\n",
    "        plot_bar(dfm[\"RMSE\"], f\"{sym} test RMSE\", os.path.join(PLOTS_DIR, f\"{sym}_rmse.png\"))\n",
    "\n",
    "        # print comparison & best model\n",
    "        print(\"Model comparison:\")\n",
    "        for m, row in dfm.iterrows():\n",
    "            print(f\"  {m:10s} -> R2: {row['R2']:.4f}, RMSE: {row['RMSE']:.2f}, MAE: {row['MAE']:.2f}\")\n",
    "        best = dfm[\"R2\"].idxmax()\n",
    "        best_stats = dfm.loc[best]\n",
    "        print(f\"\\nBest model for {sym}: {best} (R2={best_stats['R2']:.4f}, RMSE={best_stats['RMSE']:.2f}, MAE={best_stats['MAE']:.2f})\\n\")\n",
    "\n",
    "        summary.append({\n",
    "            \"Crypto\": sym,\n",
    "            \"Model\": best,\n",
    "            **best_stats.to_dict()\n",
    "        })\n",
    "\n",
    "    # consolidated summary CSV\n",
    "    summary_df = pd.DataFrame(summary)\n",
    "    summary_path = os.path.join(RESULTS_DIR, \"regression_summary.csv\")\n",
    "    summary_df.to_csv(summary_path, index=False)\n",
    "\n",
    "    # summary of best models\n",
    "    print(\"Summary of best models:\")\n",
    "    for _, row in summary_df.iterrows():\n",
    "        print(f\"{row['Crypto']} -> {row['Model']} (R2={row['R2']:.4f}, RMSE={row['RMSE']:.2f}, MAE={row['MAE']:.2f})\")\n",
    "\n",
    "    # best-model comparison plot\n",
    "    fig, ax = plt.subplots(figsize=(6,4))\n",
    "    bars = ax.bar(summary_df[\"Crypto\"], summary_df[\"R2\"])\n",
    "    ax.set_title(\"Best R² by Cryptocurrency\")\n",
    "    ax.bar_label(bars, fmt=\"%.2f\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(PLOTS_DIR, \"best_model_comparison.png\"))\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"\\ndone!\\nModels saved in:  {MODEL_DIR}\\nMetrics saved in: {RESULTS_DIR}\\nPlots saved in:   {PLOTS_DIR}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
