{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install numpy pandas matplotlib statsmodels scikit-learn joblib tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import joblib\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "# ─── suppress warnings ─────────────────────────────────────────────────────────\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ─── directories ───────────────────────────────────────────────────────────────\n",
    "PROJECT_DIR    = os.path.expanduser(\"~/User/crypto proj\")\n",
    "PREPROC_DIR    = os.path.join(PROJECT_DIR, \"data\", \"preprocessed\")\n",
    "MODEL_DIR      = os.path.join(PROJECT_DIR, \"models\", \"time_series\")\n",
    "VIS_DIR        = os.path.join(PROJECT_DIR, \"visualizations\", \"time_series\")\n",
    "SUMMARY_PATH   = os.path.join(MODEL_DIR, \"time_series_results.json\")\n",
    "\n",
    "for d in (MODEL_DIR, VIS_DIR):\n",
    "    os.makedirs(d, exist_ok=True)\n",
    "\n",
    "# ─── which coins ────────────────────────────────────────────────────────────────\n",
    "CRYPTOS = {\n",
    "    'BTC-USD': 'Bitcoin',\n",
    "    'ETH-USD': 'Ethereum',\n",
    "    'DOGE-USD': 'Dogecoin'\n",
    "}\n",
    "\n",
    "# ─── helpers ────────────────────────────────────────────────────────────────────\n",
    "def load_latest_preprocessed(symbol):\n",
    "    \"\"\"Load the most recent date-stamped preprocessed CSV for a symbol.\"\"\"\n",
    "    base = symbol.split('-')[0]\n",
    "    pattern = os.path.join(PREPROC_DIR, f\"{base}_preprocessed_*.csv\")\n",
    "    files = glob.glob(pattern)\n",
    "    if not files:\n",
    "        raise FileNotFoundError(f\"No preprocessed files found for {base}\")\n",
    "    latest = max(files, key=os.path.getmtime)\n",
    "    print(f\"Loaded {os.path.basename(latest)}\")\n",
    "    return pd.read_csv(latest, parse_dates=['Date'], index_col='Date')\n",
    "\n",
    "def check_stationarity(ts, window=12):\n",
    "    \"\"\"ADF test and rolling mean/std plot; return True if p-value<0.05.\"\"\"\n",
    "    adf = adfuller(ts.dropna(), autolag='AIC')\n",
    "    out = pd.Series(adf[:4],\n",
    "                    index=['Test Statistic','p-value','#Lags','#Observations'])\n",
    "    for k,v in adf[4].items():\n",
    "        out[f'Crit Value ({k})'] = v\n",
    "    print(out.to_string(), \"\\n\")\n",
    "    plt.figure(figsize=(10,4))\n",
    "    plt.plot(ts, label='Original')\n",
    "    plt.plot(ts.rolling(window).mean(), label='Rolling Mean')\n",
    "    plt.plot(ts.rolling(window).std(), label='Rolling Std')\n",
    "    plt.legend(); plt.title(f\"{ts.name} Stationarity\")\n",
    "    plt.savefig(os.path.join(VIS_DIR, f\"{ts.name}_stationarity.png\"))\n",
    "    plt.close()\n",
    "    return adf[1] < 0.05\n",
    "\n",
    "def make_stationary(ts):\n",
    "    \"\"\"Difference ts up to d=2 until stationary.\"\"\"\n",
    "    if check_stationarity(ts):\n",
    "        return ts, 0\n",
    "    for d in (1,2):\n",
    "        diff = ts.diff(d).dropna()\n",
    "        if check_stationarity(diff):\n",
    "            print(f\"Stationary after differencing d={d}\\n\")\n",
    "            return diff, d\n",
    "    print(\"Still non-stationary after d=2; using d=1\\n\")\n",
    "    return ts.diff(1).dropna(), 1\n",
    "\n",
    "def determine_arima_parameters(ts, d):\n",
    "    \"\"\"Plot ACF/PACF and return (p,d,q), defaults to (1,d,1).\"\"\"\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.subplot(211)\n",
    "    plot_acf(ts, ax=plt.gca(), lags=30)\n",
    "    plt.subplot(212)\n",
    "    plot_pacf(ts, ax=plt.gca(), lags=30)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(VIS_DIR, f\"{ts.name}_acf_pacf.png\"))\n",
    "    plt.close()\n",
    "    return 1, d, 1\n",
    "\n",
    "def train_arima(ts, order, train_frac=0.8):\n",
    "    \"\"\"Train ARIMA and evaluate on hold-out; save fit plot.\"\"\"\n",
    "    split = int(len(ts)*train_frac)\n",
    "    train, test = ts[:split], ts[split:]\n",
    "    model = ARIMA(train, order=order).fit()\n",
    "    preds = model.forecast(steps=len(test))\n",
    "\n",
    "    rmse = np.sqrt(mean_squared_error(test, preds))\n",
    "    mae  = mean_absolute_error(test, preds)\n",
    "    r2   = r2_score(test, preds)\n",
    "\n",
    "    plt.figure(figsize=(10,4))\n",
    "    plt.plot(train, label='Train')\n",
    "    plt.plot(test, label='Test')\n",
    "    plt.plot(preds, label=f'ARIMA{order}', color='red')\n",
    "    plt.legend(); plt.title(f\"ARIMA{order} Fit\")\n",
    "    plt.savefig(os.path.join(VIS_DIR, f\"{ts.name}_arima_fit.png\"))\n",
    "    plt.close()\n",
    "\n",
    "    return model, preds, rmse, mae, r2\n",
    "\n",
    "def forecast_arima(model, steps=30):\n",
    "    \"\"\"Forecast future and return Series with next‐day index.\"\"\"\n",
    "    fcast = model.forecast(steps=steps)\n",
    "    last = model.data.dates[-1]\n",
    "    idx = pd.date_range(start=last+timedelta(days=1), periods=steps, freq='D')\n",
    "    return pd.Series(fcast, index=idx, name='ARIMA_Forecast')\n",
    "\n",
    "def prepare_lstm(ts, look_back=60, train_frac=0.8):\n",
    "    \"\"\"Scale ts to [0,1], build look_back sequences, split train/test.\"\"\"\n",
    "    arr = ts.values.reshape(-1,1)\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled = scaler.fit_transform(arr)\n",
    "    X, y = [], []\n",
    "    for i in range(look_back, len(scaled)):\n",
    "        X.append(scaled[i-look_back:i,0])\n",
    "        y.append(scaled[i,0])\n",
    "    X, y = np.array(X), np.array(y)\n",
    "    X = X.reshape((X.shape[0], X.shape[1], 1))\n",
    "    split = int(len(X)*train_frac)\n",
    "    return X[:split], X[split:], y[:split], y[split:], scaler\n",
    "\n",
    "def train_lstm(X_tr, y_tr, X_te, y_te, scaler, name, epochs=50, batch_size=32):\n",
    "    \"\"\"Build, train LSTM, evaluate, and save fit & loss plots.\"\"\"\n",
    "    model = Sequential([\n",
    "        LSTM(50, return_sequences=True, input_shape=(X_tr.shape[1],1)),\n",
    "        Dropout(0.2),\n",
    "        LSTM(50),\n",
    "        Dropout(0.2),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    hist = model.fit(X_tr, y_tr,\n",
    "                     validation_data=(X_te, y_te),\n",
    "                     epochs=epochs, batch_size=batch_size, verbose=1)\n",
    "\n",
    "    y_pred = model.predict(X_te)\n",
    "    y_te_inv   = scaler.inverse_transform(y_te.reshape(-1,1))\n",
    "    y_pred_inv = scaler.inverse_transform(y_pred)\n",
    "\n",
    "    rmse = np.sqrt(mean_squared_error(y_te_inv, y_pred_inv))\n",
    "    mae  = mean_absolute_error(y_te_inv, y_pred_inv)\n",
    "    r2   = r2_score(y_te_inv, y_pred_inv)\n",
    "\n",
    "    # fit plot\n",
    "    plt.figure(figsize=(8,4))\n",
    "    plt.plot(y_te_inv, label='Actual')\n",
    "    plt.plot(y_pred_inv, label='Pred', color='green')\n",
    "    plt.title(f'LSTM Fit ({name})')\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(VIS_DIR, f\"{name}_lstm_fit.png\"))\n",
    "    plt.close()\n",
    "\n",
    "    # loss plot\n",
    "    plt.figure(figsize=(6,3))\n",
    "    plt.plot(hist.history['loss'], label='train')\n",
    "    plt.plot(hist.history['val_loss'], label='val')\n",
    "    plt.title(f'LSTM Loss ({name})')\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(VIS_DIR, f\"{name}_lstm_loss.png\"))\n",
    "    plt.close()\n",
    "\n",
    "    return model, rmse, mae, r2, scaler\n",
    "\n",
    "def forecast_lstm(model, last_seq, scaler, steps=30):\n",
    "    \"\"\"Auto-regress for steps ahead, return inverse-transformed Series.\"\"\"\n",
    "    seq = last_seq.copy()\n",
    "    preds = []\n",
    "    for _ in range(steps):\n",
    "        p = model.predict(seq.reshape(1, -1, 1))[0,0]\n",
    "        preds.append(p)\n",
    "        seq = np.roll(seq, -1)\n",
    "        seq[-1] = p\n",
    "    inv = scaler.inverse_transform(np.array(preds).reshape(-1,1))\n",
    "    idx = pd.date_range(start=datetime.now()+timedelta(days=1),\n",
    "                        periods=steps, freq='D')\n",
    "    return pd.Series(inv.flatten(), index=idx, name='LSTM_Forecast')\n",
    "\n",
    "# ─── main ───────────────────────────────────────────────────────────────────────\n",
    "if __name__ == \"__main__\":\n",
    "    summary = {}\n",
    "\n",
    "    print(\"Starting time series modeling...\\n\")\n",
    "    for symbol, nice in CRYPTOS.items():\n",
    "        print(f\"=== {nice} ===\")\n",
    "\n",
    "        df = load_latest_preprocessed(symbol)\n",
    "        ts = df['Close']\n",
    "        ts.name = nice\n",
    "\n",
    "        # raw plot\n",
    "        plt.figure(figsize=(8,3))\n",
    "        plt.plot(ts); plt.title(f\"{nice} Close\")\n",
    "        plt.savefig(os.path.join(VIS_DIR, f\"{nice}_raw.png\"))\n",
    "        plt.close()\n",
    "\n",
    "        # stationarity\n",
    "        ts_stat, d = make_stationary(ts)\n",
    "\n",
    "        # ARIMA\n",
    "        p, _, q = determine_arima_parameters(ts_stat, d)\n",
    "        print(f\"→ ARIMA order: ({p},{d},{q})\")\n",
    "        ar_model, ar_preds, ar_rmse, ar_mae, ar_r2 = train_arima(ts, (p,d,q))\n",
    "        ar_fcast = forecast_arima(ar_model, steps=30)\n",
    "\n",
    "        # ARIMA forecast plot\n",
    "        plt.figure(figsize=(8,3))\n",
    "        plt.plot(ts[-90:], label='Last 90d')\n",
    "        plt.plot(ar_fcast, label='ARIMA')\n",
    "        plt.legend(); plt.title(f\"{nice} ARIMA 30d\")\n",
    "        plt.savefig(os.path.join(VIS_DIR, f\"{nice}_arima_fcast.png\"))\n",
    "        plt.close()\n",
    "\n",
    "        # LSTM\n",
    "        X_tr, X_te, y_tr, y_te, scaler = prepare_lstm(ts)\n",
    "        lstm_model, lstm_rmse, lstm_mae, lstm_r2, scaler = train_lstm(\n",
    "            X_tr, y_tr, X_te, y_te, scaler, nice\n",
    "        )\n",
    "        last_seq = X_te[-1].flatten()\n",
    "        lstm_fcast = forecast_lstm(lstm_model, last_seq, scaler, steps=30)\n",
    "\n",
    "        # forecast comparison\n",
    "        plt.figure(figsize=(8,3))\n",
    "        plt.plot(ts[-90:], label='Last 90d')\n",
    "        plt.plot(ar_fcast, label='ARIMA')\n",
    "        plt.plot(lstm_fcast, label='LSTM')\n",
    "        plt.legend(); plt.title(f\"{nice} 30d Forecasts\")\n",
    "        plt.savefig(os.path.join(VIS_DIR, f\"{nice}_forecast_comp.png\"))\n",
    "        plt.close()\n",
    "\n",
    "        # save models and scaler\n",
    "        joblib.dump(ar_model, os.path.join(MODEL_DIR, f\"{nice}_arima.pkl\"))\n",
    "        lstm_model.save(os.path.join(MODEL_DIR, f\"{nice}_lstm.h5\"))\n",
    "        joblib.dump(scaler, os.path.join(MODEL_DIR, f\"{nice}_scaler.pkl\"))\n",
    "\n",
    "        summary[nice] = {\n",
    "            'ARIMA': {'order': (p,d,q), 'rmse': ar_rmse, 'mae': ar_mae, 'r2': ar_r2},\n",
    "            'LSTM':  {'rmse': lstm_rmse, 'mae': lstm_mae, 'r2': lstm_r2}\n",
    "        }\n",
    "\n",
    "    # write summary\n",
    "    with open(SUMMARY_PATH, 'w') as f:\n",
    "        json.dump(summary, f, indent=2)\n",
    "\n",
    "    print(f\"\\nDone! Models in: {MODEL_DIR}\\nPlots in: {VIS_DIR}\\nSummary at: {SUMMARY_PATH}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
