{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas numpy matplotlib seaborn scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# ─── suppress warnings ─────────────────────────────────────────────────────────\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ─── directories ───────────────────────────────────────────────────────────────\n",
    "PROJECT_DIR          = os.path.expanduser(\"~/User/crypto proj\")\n",
    "DATA_DIR             = os.path.join(PROJECT_DIR, \"data\")\n",
    "PREPROC_DIR          = os.path.join(DATA_DIR, \"preprocessed\")\n",
    "VIS_DIR              = os.path.join(PROJECT_DIR, \"visualizations\", \"clustering\")\n",
    "CLUSTER_RESULTS_PATH = os.path.join(PROJECT_DIR, \"models\", \"clustering_results.json\")\n",
    "\n",
    "os.makedirs(VIS_DIR, exist_ok=True)\n",
    "os.makedirs(os.path.dirname(CLUSTER_RESULTS_PATH), exist_ok=True)\n",
    "\n",
    "# ─── constants ────────────────────────────────────────────────────────────────\n",
    "COINS   = {'BTC': 'Bitcoin', 'ETH': 'Ethereum', 'DOGE': 'Dogecoin'}\n",
    "EPS_MAP = {'Bitcoin': 1.5, 'Ethereum': 1.2, 'Dogecoin': 0.5}\n",
    "\n",
    "# ─── helpers ──────────────────────────────────────────────────────────────────\n",
    "def load_preprocessed(symbol: str) -> pd.DataFrame:\n",
    "    \"\"\"Load most recent date‐stamped preprocessed CSV for a symbol.\"\"\"\n",
    "    pattern = os.path.join(PREPROC_DIR, f\"{symbol}_preprocessed_*.csv\")\n",
    "    files = glob.glob(pattern)\n",
    "    if not files:\n",
    "        raise FileNotFoundError(f\"No preprocessed files for {symbol}\")\n",
    "    latest = max(files, key=os.path.getmtime)\n",
    "    print(f\"Loaded {os.path.basename(latest)}\")\n",
    "    return pd.read_csv(latest, parse_dates=[\"Date\"], index_col=\"Date\")\n",
    "\n",
    "def prepare_clustering_data(df: pd.DataFrame):\n",
    "    \"\"\"Select features, drop NaNs, and standard‐scale.\"\"\"\n",
    "    cols = [\n",
    "        'Close','Volume','Daily_Return',\n",
    "        'Volatility_30','RSI','MACD_Hist',\n",
    "        'Weekly_Return','MA30'\n",
    "    ]\n",
    "    feats = df[cols].select_dtypes(include=[np.number]).dropna()\n",
    "    scaler = StandardScaler()\n",
    "    data_scaled = scaler.fit_transform(feats)\n",
    "    return data_scaled, feats\n",
    "\n",
    "def determine_optimal_clusters(data: np.ndarray, max_k: int = 15) -> int:\n",
    "    \"\"\"Compute elbow & silhouette and return k with highest silhouette.\"\"\"\n",
    "    ks = range(2, max_k+1)\n",
    "    inertias, silhouettes = [], []\n",
    "    for k in ks:\n",
    "        km = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "        labels = km.fit_predict(data)\n",
    "        inertias.append(km.inertia_)\n",
    "        silhouettes.append(silhouette_score(data, labels))\n",
    "    # plot elbow & silhouette\n",
    "    fig, axes = plt.subplots(1,2, figsize=(12,5))\n",
    "    axes[0].plot(ks, inertias, 'o-'); axes[0].set(title=\"Elbow\", xlabel=\"k\", ylabel=\"Inertia\")\n",
    "    axes[1].plot(ks, silhouettes, 'o-'); axes[1].set(title=\"Silhouette\", xlabel=\"k\", ylabel=\"Score\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(VIS_DIR, \"elbow_silhouette.png\"))\n",
    "    plt.close()\n",
    "    best_k = ks[int(np.argmax(silhouettes))]\n",
    "    print(f\" → Optimal k by silhouette: {best_k}\")\n",
    "    return best_k\n",
    "\n",
    "def perform_clustering(data, k, feats, coin_name, eps):\n",
    "    \"\"\"Run KMeans, DBSCAN, Agglomerative, GMM and pick best by silhouette.\"\"\"\n",
    "    algorithms = {\n",
    "        'KMeans': KMeans(n_clusters=k, random_state=42, n_init=10),\n",
    "        'DBSCAN': DBSCAN(eps=eps, min_samples=7),\n",
    "        'Agglomerative': AgglomerativeClustering(n_clusters=k),\n",
    "        'GMM': GaussianMixture(n_components=k, random_state=42)\n",
    "    }\n",
    "    labels = {}\n",
    "    labels['KMeans']       = algorithms['KMeans'].fit_predict(data)\n",
    "    labels['DBSCAN']       = algorithms['DBSCAN'].fit_predict(data)\n",
    "    labels['Agglomerative']= algorithms['Agglomerative'].fit_predict(data)\n",
    "    algorithms['GMM'].fit(data)\n",
    "    labels['GMM']          = algorithms['GMM'].predict(data)\n",
    "\n",
    "    # silhouette only for algorithms without label -1\n",
    "    scores = {\n",
    "        alg: silhouette_score(data, lab)\n",
    "        for alg, lab in labels.items()\n",
    "        if alg != 'DBSCAN'\n",
    "    }\n",
    "    best_alg = max(scores, key=scores.get)\n",
    "    print(f\" → Silhouette scores: {scores}\")\n",
    "    print(f\" → Best algorithm: {best_alg}\")\n",
    "\n",
    "    dfc = feats.copy()\n",
    "    for alg, lab in labels.items():\n",
    "        dfc[alg] = lab\n",
    "    dfc['Best_Cluster'] = labels[best_alg]\n",
    "\n",
    "    # save cluster assignments\n",
    "    out_assign = os.path.join(PREPROC_DIR, f\"{coin_name}_clustering.csv\")\n",
    "    dfc.to_csv(out_assign)\n",
    "    print(f\"Saved assignments to {out_assign}\")\n",
    "\n",
    "    return dfc, best_alg, scores\n",
    "\n",
    "def analyze_clusters(dfc, best_alg, coin_name):\n",
    "    \"\"\"Compute cluster statistics and regimes; save stats & heatmap.\"\"\"\n",
    "    grp = dfc.groupby(best_alg)\n",
    "    stats = grp.agg({\n",
    "        'Close':['mean','std','min','max'],\n",
    "        'Volume':['mean','std'],\n",
    "        'Daily_Return':['mean','std'],\n",
    "        'Volatility_30':['mean','std'],\n",
    "        'RSI':['mean','std']\n",
    "    })\n",
    "    stats.columns = ['_'.join(col) for col in stats.columns]\n",
    "    counts = grp.size() / len(dfc) * 100\n",
    "    stats['Percentage'] = counts\n",
    "\n",
    "    out_stats = os.path.join(PREPROC_DIR, f\"{coin_name}_cluster_stats.csv\")\n",
    "    stats.to_csv(out_stats)\n",
    "    print(f\"Saved cluster stats to {out_stats}\")\n",
    "\n",
    "    # heatmap\n",
    "    hm_cols = ['Close_mean','Daily_Return_mean','Volatility_30_mean','RSI_mean','Volume_mean','Percentage']\n",
    "    plt.figure(figsize=(10,6))\n",
    "    sns.heatmap(stats[hm_cols], annot=True, fmt=\".2f\", cmap='coolwarm')\n",
    "    plt.title(f\"{coin_name} Cluster Characteristics\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(VIS_DIR, f\"{coin_name}_cluster_stats.png\"))\n",
    "    plt.close()\n",
    "\n",
    "    # define regimes\n",
    "    regimes = {}\n",
    "    for cl in stats.index:\n",
    "        mret = stats.loc[cl, 'Daily_Return_mean']\n",
    "        mrsi = stats.loc[cl, 'RSI_mean']\n",
    "        if mret > 0.01: regime = \"Bull\"\n",
    "        elif mret < -0.01: regime = \"Bear\"\n",
    "        else: regime = \"Sideways\"\n",
    "        if mrsi > 70: regime += \"-OB\"\n",
    "        elif mrsi < 30: regime += \"-OS\"\n",
    "        regimes[cl] = regime\n",
    "\n",
    "    print(f\" → Regimes mapping: {regimes}\")\n",
    "    return regimes\n",
    "\n",
    "def visualize(dfc, data, best_alg, coin_name):\n",
    "    \"\"\"PCA scatter, time scatter, market regime plot.\"\"\"\n",
    "    # PCA\n",
    "    pca = PCA(n_components=2)\n",
    "    pcs = pca.fit_transform(data)\n",
    "    dfp = pd.DataFrame(pcs, columns=['PC1','PC2'], index=dfc.index)\n",
    "    dfp['Cluster'] = dfc[best_alg]\n",
    "    plt.figure(figsize=(8,6))\n",
    "    plt.scatter(dfp['PC1'], dfp['PC2'], c=dfp['Cluster'], cmap='tab10', alpha=0.6)\n",
    "    plt.title(f\"{coin_name} PCA clusters ({best_alg})\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(VIS_DIR, f\"{coin_name}_{best_alg}_pca.png\"))\n",
    "    plt.close()\n",
    "\n",
    "    # time series colored\n",
    "    plt.figure(figsize=(10,4))\n",
    "    plt.scatter(dfc.index, dfc['Close'], c=dfc[best_alg], cmap='tab10', s=10)\n",
    "    plt.title(f\"{coin_name} Price over time ({best_alg})\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(VIS_DIR, f\"{coin_name}_{best_alg}_time.png\"))\n",
    "    plt.close()\n",
    "\n",
    "    # market regimes\n",
    "    dfc['Regime'] = dfc[best_alg].map(regimes)\n",
    "    uniq = dfc['Regime'].unique()\n",
    "    colors = plt.cm.tab20(np.linspace(0,1,len(uniq)))\n",
    "    cmap = dict(zip(uniq, colors))\n",
    "    plt.figure(figsize=(12,5))\n",
    "    plt.plot(dfc.index, dfc['Close'], color='k', lw=1)\n",
    "    for reg in uniq:\n",
    "        sub = dfc[dfc['Regime'] == reg]\n",
    "        plt.scatter(sub.index, sub['Close'], color=cmap[reg], label=reg, s=8)\n",
    "    plt.title(f\"{coin_name} Market Regimes\")\n",
    "    plt.legend(loc='upper left', ncol=2)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(VIS_DIR, f\"{coin_name}_market_regimes.png\"))\n",
    "    plt.close()\n",
    "\n",
    "# ─── main ─────────────────────────────────────────────────────────────────────\n",
    "if __name__ == \"__main__\":\n",
    "    clustering_results = {}\n",
    "\n",
    "    print(\"Starting clustering analysis...\\n\")\n",
    "    for sym, nice in COINS.items():\n",
    "        print(f\"=== {nice} ===\")\n",
    "        df = load_preprocessed(sym)\n",
    "\n",
    "        data, feats = prepare_clustering_data(df)\n",
    "        k = determine_optimal_clusters(data)\n",
    "        dfc, best_alg, scores = perform_clustering(data, k, feats, nice, EPS_MAP[nice])\n",
    "        regimes = analyze_clusters(dfc, best_alg, nice)\n",
    "        visualize(dfc, data, best_alg, nice)\n",
    "\n",
    "        clustering_results[nice] = {\n",
    "            'Optimal_Clusters': k,\n",
    "            'Best_Algorithm': best_alg,\n",
    "            'Silhouette': float(scores[best_alg])\n",
    "        }\n",
    "        print(\"\\n\")\n",
    "\n",
    "    # save summary JSON\n",
    "    with open(CLUSTER_RESULTS_PATH, 'w') as f:\n",
    "        json.dump(clustering_results, f, indent=2)\n",
    "    print(f\"Saved clustering summary to {CLUSTER_RESULTS_PATH}\")\n",
    "\n",
    "    # summary bar chart\n",
    "    names = list(clustering_results.keys())\n",
    "    sils  = [clustering_results[n]['Silhouette'] for n in names]\n",
    "    plt.figure(figsize=(6,4))\n",
    "    bars = plt.bar(names, sils, color=['C0','C1','C2'])\n",
    "    plt.title(\"Best clustering silhouette by coin\")\n",
    "    plt.ylabel(\"Silhouette score\")\n",
    "    plt.bar_label(bars, fmt=\"%.2f\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(VIS_DIR, \"best_silhouette_comparison.png\"))\n",
    "    plt.close()\n",
    "\n",
    "    print(\"\\nClustering analysis complete. Visuals in\", VIS_DIR)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
